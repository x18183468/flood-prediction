{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ctgan in /home/ec2-user/.local/lib/python3.6/site-packages (0.2.1)\n",
      "Requirement already satisfied: scikit-learn<0.23,>=0.21 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from ctgan) (0.22.1)\n",
      "Requirement already satisfied: torchvision<1,>=0.4.2 in /home/ec2-user/.local/lib/python3.6/site-packages (from ctgan) (0.6.1)\n",
      "Requirement already satisfied: numpy<2,>=1.17.4 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from ctgan) (1.18.1)\n",
      "Requirement already satisfied: pandas<0.26,>=0.24 in /home/ec2-user/.local/lib/python3.6/site-packages (from ctgan) (0.25.3)\n",
      "Requirement already satisfied: torch<2,>=1.0 in /home/ec2-user/.local/lib/python3.6/site-packages (from ctgan) (1.5.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from scikit-learn<0.23,>=0.21->ctgan) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from scikit-learn<0.23,>=0.21->ctgan) (0.14.1)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from torchvision<1,>=0.4.2->ctgan) (7.0.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from pandas<0.26,>=0.24->ctgan) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from pandas<0.26,>=0.24->ctgan) (2.8.1)\n",
      "Requirement already satisfied: future in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from torch<2,>=1.0->ctgan) (0.18.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from python-dateutil>=2.6.1->pandas<0.26,>=0.24->ctgan) (1.14.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/mxnet_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#EXECUTE THIS COMMAND WITH KERNAL SET TO \"conda_mxnet_p36\". ONLY THIS KERNALCAN INSTALL EXTERNAL LIBRARIES.\n",
    "\n",
    "! pip install --user ctgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "\n",
    "from ctgan import CTGANSynthesizer\n",
    "import pandas as pd\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>river</th>\n",
       "      <th>rain</th>\n",
       "      <th>temperature</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>wind_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-11T14:45</td>\n",
       "      <td>7.659</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.37</td>\n",
       "      <td>270.0</td>\n",
       "      <td>6.433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-11T14:30</td>\n",
       "      <td>7.578</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.46</td>\n",
       "      <td>267.0</td>\n",
       "      <td>6.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-11T14:15</td>\n",
       "      <td>7.442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.35</td>\n",
       "      <td>268.0</td>\n",
       "      <td>6.334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-11T14:00</td>\n",
       "      <td>7.252</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.41</td>\n",
       "      <td>267.0</td>\n",
       "      <td>6.108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-11T13:45</td>\n",
       "      <td>7.019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.83</td>\n",
       "      <td>268.0</td>\n",
       "      <td>5.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2753</th>\n",
       "      <td>2020-06-12T01:00</td>\n",
       "      <td>6.078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.94</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2754</th>\n",
       "      <td>2020-06-12T00:45</td>\n",
       "      <td>5.702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.84</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2755</th>\n",
       "      <td>2020-06-12T00:30</td>\n",
       "      <td>5.332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.71</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756</th>\n",
       "      <td>2020-06-12T00:15</td>\n",
       "      <td>4.932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.61</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2757</th>\n",
       "      <td>2020-06-12T00:00</td>\n",
       "      <td>4.540</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.53</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2758 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time  river  rain  temperature  wind_direction  wind_speed\n",
       "0     2020-07-11T14:45  7.659   0.0        18.37           270.0       6.433\n",
       "1     2020-07-11T14:30  7.578   0.0        17.46           267.0       6.048\n",
       "2     2020-07-11T14:15  7.442   0.0        16.35           268.0       6.334\n",
       "3     2020-07-11T14:00  7.252   0.0        16.41           267.0       6.108\n",
       "4     2020-07-11T13:45  7.019   0.0        16.83           268.0       5.325\n",
       "...                ...    ...   ...          ...             ...         ...\n",
       "2753  2020-06-12T01:00  6.078   0.0        11.94             4.0       4.914\n",
       "2754  2020-06-12T00:45  5.702   0.0        11.84             5.0       5.201\n",
       "2755  2020-06-12T00:30  5.332   0.0        11.71             8.0       5.099\n",
       "2756  2020-06-12T00:15  4.932   0.0        11.61             4.0       5.554\n",
       "2757  2020-06-12T00:00  4.540   0.0        11.53             7.0       5.272\n",
       "\n",
       "[2758 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import source file\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "bucket = 'flood-prediction-master-dataset'\n",
    "key = 'ml-sensor-data-15-min/ml_sensor_data_15_min.csv'\n",
    "\n",
    "obj = s3.get_object(Bucket= bucket,Key= key)\n",
    "\n",
    "file = pd.read_csv(obj['Body'],names=[\"time\",\"river\",\"rain\",\"temperature\",\"wind_direction\",\"wind_speed\"])\n",
    "\n",
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify the headers to GAN\n",
    "\n",
    "discrete_columns = [\n",
    "    'time',\n",
    "    'river',\n",
    "    'rain',\n",
    "    'temperature',\n",
    "    'wind_direction',\n",
    "    'wind_speed'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating instance\n",
    "\n",
    "ctgan = CTGANSynthesizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss G: 6.5076, Loss D: -0.0168\n",
      "Epoch 2, Loss G: 6.3924, Loss D: -0.0505\n",
      "Epoch 3, Loss G: 6.5633, Loss D: -0.0877\n",
      "Epoch 4, Loss G: 6.5609, Loss D: -0.1126\n",
      "Epoch 5, Loss G: 6.5976, Loss D: -0.1468\n",
      "Epoch 6, Loss G: 6.5404, Loss D: -0.1767\n",
      "Epoch 7, Loss G: 6.4405, Loss D: -0.1780\n",
      "Epoch 8, Loss G: 6.3071, Loss D: -0.1633\n",
      "Epoch 9, Loss G: 6.3667, Loss D: -0.1390\n",
      "Epoch 10, Loss G: 6.3521, Loss D: -0.1256\n",
      "Epoch 11, Loss G: 6.3622, Loss D: -0.1235\n",
      "Epoch 12, Loss G: 6.2453, Loss D: -0.0958\n",
      "Epoch 13, Loss G: 6.2343, Loss D: -0.1127\n",
      "Epoch 14, Loss G: 6.3644, Loss D: -0.0780\n",
      "Epoch 15, Loss G: 6.3937, Loss D: -0.0471\n",
      "Epoch 16, Loss G: 6.3570, Loss D: -0.0339\n",
      "Epoch 17, Loss G: 6.4664, Loss D: -0.0477\n",
      "Epoch 18, Loss G: 6.2243, Loss D: -0.0577\n",
      "Epoch 19, Loss G: 6.4095, Loss D: -0.0655\n",
      "Epoch 20, Loss G: 6.1731, Loss D: -0.0443\n",
      "Epoch 21, Loss G: 6.4040, Loss D: -0.0612\n",
      "Epoch 22, Loss G: 6.2055, Loss D: -0.0365\n",
      "Epoch 23, Loss G: 6.1212, Loss D: -0.0222\n",
      "Epoch 24, Loss G: 6.2856, Loss D: -0.0304\n",
      "Epoch 25, Loss G: 6.3225, Loss D: -0.0093\n",
      "Epoch 26, Loss G: 6.0282, Loss D: -0.0335\n",
      "Epoch 27, Loss G: 6.1253, Loss D: -0.0450\n",
      "Epoch 28, Loss G: 5.9612, Loss D: -0.0163\n",
      "Epoch 29, Loss G: 6.1862, Loss D: -0.0187\n",
      "Epoch 30, Loss G: 6.0408, Loss D: -0.0251\n",
      "Epoch 31, Loss G: 6.1994, Loss D: -0.0161\n",
      "Epoch 32, Loss G: 6.1214, Loss D: -0.0226\n",
      "Epoch 33, Loss G: 5.9834, Loss D: -0.0241\n",
      "Epoch 34, Loss G: 5.9438, Loss D: -0.0101\n",
      "Epoch 35, Loss G: 6.1648, Loss D: -0.0175\n",
      "Epoch 36, Loss G: 6.0145, Loss D: -0.0215\n",
      "Epoch 37, Loss G: 6.0344, Loss D: -0.0368\n",
      "Epoch 38, Loss G: 6.0176, Loss D: -0.0065\n",
      "Epoch 39, Loss G: 6.1163, Loss D: -0.0108\n",
      "Epoch 40, Loss G: 5.9711, Loss D: -0.0110\n",
      "Epoch 41, Loss G: 5.8752, Loss D: -0.0425\n",
      "Epoch 42, Loss G: 6.0728, Loss D: -0.0374\n",
      "Epoch 43, Loss G: 5.9219, Loss D: -0.0212\n",
      "Epoch 44, Loss G: 5.9675, Loss D: -0.0270\n",
      "Epoch 45, Loss G: 5.9309, Loss D: -0.0031\n",
      "Epoch 46, Loss G: 5.7966, Loss D: -0.0258\n",
      "Epoch 47, Loss G: 5.9620, Loss D: -0.0125\n",
      "Epoch 48, Loss G: 5.8828, Loss D: -0.0457\n",
      "Epoch 49, Loss G: 5.8584, Loss D: -0.0275\n",
      "Epoch 50, Loss G: 5.7619, Loss D: -0.0222\n",
      "Epoch 51, Loss G: 5.8374, Loss D: -0.0271\n",
      "Epoch 52, Loss G: 5.6422, Loss D: -0.0200\n",
      "Epoch 53, Loss G: 5.6474, Loss D: -0.0398\n",
      "Epoch 54, Loss G: 6.0105, Loss D: -0.0287\n",
      "Epoch 55, Loss G: 5.7603, Loss D: -0.0145\n",
      "Epoch 56, Loss G: 5.7656, Loss D: -0.0352\n",
      "Epoch 57, Loss G: 5.9676, Loss D: -0.0265\n",
      "Epoch 58, Loss G: 5.7251, Loss D: -0.0180\n",
      "Epoch 59, Loss G: 5.2165, Loss D: -0.0395\n",
      "Epoch 60, Loss G: 5.7156, Loss D: -0.0348\n",
      "Epoch 61, Loss G: 5.4431, Loss D: -0.0448\n",
      "Epoch 62, Loss G: 5.3178, Loss D: -0.0371\n",
      "Epoch 63, Loss G: 5.1490, Loss D: -0.0348\n",
      "Epoch 64, Loss G: 5.3554, Loss D: -0.0424\n",
      "Epoch 65, Loss G: 5.1151, Loss D: -0.0329\n",
      "Epoch 66, Loss G: 5.1886, Loss D: -0.0345\n",
      "Epoch 67, Loss G: 4.9785, Loss D: -0.0441\n",
      "Epoch 68, Loss G: 5.0813, Loss D: -0.0690\n",
      "Epoch 69, Loss G: 4.9806, Loss D: -0.0682\n",
      "Epoch 70, Loss G: 5.1687, Loss D: -0.0364\n",
      "Epoch 71, Loss G: 5.0679, Loss D: -0.0608\n",
      "Epoch 72, Loss G: 4.8640, Loss D: -0.0078\n",
      "Epoch 73, Loss G: 5.0354, Loss D: -0.0522\n",
      "Epoch 74, Loss G: 4.9333, Loss D: -0.0558\n",
      "Epoch 75, Loss G: 4.7991, Loss D: -0.0472\n",
      "Epoch 76, Loss G: 4.6771, Loss D: -0.0498\n",
      "Epoch 77, Loss G: 4.6931, Loss D: -0.0413\n",
      "Epoch 78, Loss G: 4.7031, Loss D: -0.0420\n",
      "Epoch 79, Loss G: 4.2858, Loss D: -0.0521\n",
      "Epoch 80, Loss G: 4.4759, Loss D: -0.0507\n",
      "Epoch 81, Loss G: 4.3732, Loss D: -0.0536\n",
      "Epoch 82, Loss G: 4.5053, Loss D: -0.0581\n",
      "Epoch 83, Loss G: 4.4238, Loss D: -0.0346\n",
      "Epoch 84, Loss G: 4.0565, Loss D: -0.0335\n",
      "Epoch 85, Loss G: 3.9566, Loss D: -0.0454\n",
      "Epoch 86, Loss G: 4.0702, Loss D: -0.0345\n",
      "Epoch 87, Loss G: 4.1145, Loss D: -0.0297\n",
      "Epoch 88, Loss G: 3.8299, Loss D: -0.0085\n",
      "Epoch 89, Loss G: 4.0934, Loss D: -0.0343\n",
      "Epoch 90, Loss G: 3.7143, Loss D: -0.0450\n",
      "Epoch 91, Loss G: 3.7933, Loss D: -0.0390\n",
      "Epoch 92, Loss G: 3.7057, Loss D: -0.0415\n",
      "Epoch 93, Loss G: 3.4912, Loss D: -0.0298\n",
      "Epoch 94, Loss G: 3.6396, Loss D: -0.0404\n",
      "Epoch 95, Loss G: 3.5406, Loss D: -0.0319\n",
      "Epoch 96, Loss G: 3.6571, Loss D: -0.0432\n",
      "Epoch 97, Loss G: 3.3490, Loss D: -0.0264\n",
      "Epoch 98, Loss G: 3.4689, Loss D: -0.0265\n",
      "Epoch 99, Loss G: 3.2192, Loss D: -0.0114\n",
      "Epoch 100, Loss G: 3.3159, Loss D: -0.0323\n",
      "Epoch 101, Loss G: 3.1020, Loss D: -0.0353\n",
      "Epoch 102, Loss G: 3.0516, Loss D: -0.0545\n",
      "Epoch 103, Loss G: 3.1557, Loss D: -0.0295\n",
      "Epoch 104, Loss G: 2.9200, Loss D: -0.0413\n",
      "Epoch 105, Loss G: 2.8091, Loss D: -0.0367\n",
      "Epoch 106, Loss G: 2.8317, Loss D: -0.0298\n",
      "Epoch 107, Loss G: 2.7804, Loss D: -0.0185\n",
      "Epoch 108, Loss G: 2.9671, Loss D: -0.0276\n",
      "Epoch 109, Loss G: 2.8497, Loss D: -0.0095\n",
      "Epoch 110, Loss G: 2.7350, Loss D: -0.0220\n",
      "Epoch 111, Loss G: 2.8360, Loss D: -0.0403\n",
      "Epoch 112, Loss G: 2.4762, Loss D: -0.0041\n",
      "Epoch 113, Loss G: 2.3894, Loss D: -0.0023\n",
      "Epoch 114, Loss G: 2.4464, Loss D: -0.0459\n",
      "Epoch 115, Loss G: 2.3595, Loss D: -0.0203\n",
      "Epoch 116, Loss G: 2.3026, Loss D: -0.0230\n",
      "Epoch 117, Loss G: 2.2263, Loss D: -0.0250\n",
      "Epoch 118, Loss G: 2.1687, Loss D: -0.0238\n",
      "Epoch 119, Loss G: 2.1670, Loss D: -0.0302\n",
      "Epoch 120, Loss G: 2.0958, Loss D: -0.0153\n",
      "Epoch 121, Loss G: 1.9801, Loss D: -0.0486\n",
      "Epoch 122, Loss G: 1.8612, Loss D: -0.0342\n",
      "Epoch 123, Loss G: 1.9413, Loss D: -0.0130\n",
      "Epoch 124, Loss G: 1.8210, Loss D: -0.0180\n",
      "Epoch 125, Loss G: 1.7599, Loss D: -0.0292\n",
      "Epoch 126, Loss G: 1.9557, Loss D: -0.0159\n",
      "Epoch 127, Loss G: 1.6616, Loss D: -0.0289\n",
      "Epoch 128, Loss G: 1.5190, Loss D: -0.0184\n",
      "Epoch 129, Loss G: 1.5093, Loss D: -0.0154\n",
      "Epoch 130, Loss G: 1.5812, Loss D: -0.0256\n",
      "Epoch 131, Loss G: 1.3440, Loss D: -0.0346\n",
      "Epoch 132, Loss G: 1.5513, Loss D: -0.0176\n",
      "Epoch 133, Loss G: 1.3452, Loss D: -0.0220\n",
      "Epoch 134, Loss G: 1.4143, Loss D: -0.0201\n",
      "Epoch 135, Loss G: 1.2117, Loss D: -0.0194\n",
      "Epoch 136, Loss G: 1.2339, Loss D: -0.0273\n",
      "Epoch 137, Loss G: 1.1558, Loss D: 0.0003\n",
      "Epoch 138, Loss G: 1.1465, Loss D: -0.0196\n",
      "Epoch 139, Loss G: 1.1619, Loss D: -0.0218\n",
      "Epoch 140, Loss G: 1.2015, Loss D: -0.0464\n",
      "Epoch 141, Loss G: 1.0348, Loss D: -0.0251\n",
      "Epoch 142, Loss G: 1.0328, Loss D: -0.0272\n",
      "Epoch 143, Loss G: 0.8942, Loss D: -0.0082\n",
      "Epoch 144, Loss G: 0.9568, Loss D: -0.0245\n",
      "Epoch 145, Loss G: 1.0235, Loss D: -0.0163\n",
      "Epoch 146, Loss G: 0.9353, Loss D: -0.0225\n",
      "Epoch 147, Loss G: 0.8241, Loss D: -0.0141\n",
      "Epoch 148, Loss G: 0.9353, Loss D: -0.0116\n",
      "Epoch 149, Loss G: 0.7536, Loss D: -0.0287\n",
      "Epoch 150, Loss G: 0.7481, Loss D: -0.0167\n",
      "Epoch 151, Loss G: 0.6787, Loss D: -0.0081\n",
      "Epoch 152, Loss G: 0.6104, Loss D: -0.0097\n",
      "Epoch 153, Loss G: 0.6590, Loss D: -0.0232\n",
      "Epoch 154, Loss G: 0.7604, Loss D: -0.0214\n",
      "Epoch 155, Loss G: 0.6646, Loss D: -0.0195\n",
      "Epoch 156, Loss G: 0.6394, Loss D: -0.0173\n",
      "Epoch 157, Loss G: 0.7301, Loss D: -0.0087\n",
      "Epoch 158, Loss G: 0.5783, Loss D: -0.0237\n",
      "Epoch 159, Loss G: 0.6788, Loss D: -0.0284\n",
      "Epoch 160, Loss G: 0.5976, Loss D: -0.0296\n",
      "Epoch 161, Loss G: 0.5737, Loss D: -0.0086\n",
      "Epoch 162, Loss G: 0.5432, Loss D: -0.0228\n",
      "Epoch 163, Loss G: 0.4811, Loss D: -0.0045\n",
      "Epoch 164, Loss G: 0.4834, Loss D: -0.0362\n",
      "Epoch 165, Loss G: 0.4377, Loss D: -0.0158\n",
      "Epoch 166, Loss G: 0.5171, Loss D: -0.0263\n",
      "Epoch 167, Loss G: 0.4127, Loss D: -0.0463\n",
      "Epoch 168, Loss G: 0.4509, Loss D: -0.0286\n",
      "Epoch 169, Loss G: 0.3638, Loss D: -0.0245\n",
      "Epoch 170, Loss G: 0.3724, Loss D: -0.0113\n",
      "Epoch 171, Loss G: 0.4340, Loss D: -0.0213\n",
      "Epoch 172, Loss G: 0.4384, Loss D: -0.0137\n",
      "Epoch 173, Loss G: 0.4758, Loss D: -0.0042\n",
      "Epoch 174, Loss G: 0.4327, Loss D: -0.0194\n",
      "Epoch 175, Loss G: 0.3799, Loss D: -0.0304\n",
      "Epoch 176, Loss G: 0.3998, Loss D: -0.0122\n",
      "Epoch 177, Loss G: 0.3781, Loss D: -0.0142\n",
      "Epoch 178, Loss G: 0.3762, Loss D: -0.0292\n",
      "Epoch 179, Loss G: 0.3314, Loss D: -0.0271\n",
      "Epoch 180, Loss G: 0.3392, Loss D: -0.0028\n",
      "Epoch 181, Loss G: 0.2973, Loss D: -0.0203\n",
      "Epoch 182, Loss G: 0.3054, Loss D: -0.0249\n",
      "Epoch 183, Loss G: 0.3392, Loss D: -0.0165\n",
      "Epoch 184, Loss G: 0.3375, Loss D: -0.0207\n",
      "Epoch 185, Loss G: 0.2413, Loss D: -0.0156\n",
      "Epoch 186, Loss G: 0.3071, Loss D: -0.0001\n",
      "Epoch 187, Loss G: 0.2946, Loss D: -0.0130\n",
      "Epoch 188, Loss G: 0.2863, Loss D: -0.0164\n",
      "Epoch 189, Loss G: 0.3263, Loss D: -0.0105\n",
      "Epoch 190, Loss G: 0.2240, Loss D: -0.0216\n",
      "Epoch 191, Loss G: 0.2733, Loss D: -0.0268\n",
      "Epoch 192, Loss G: 0.2841, Loss D: -0.0390\n",
      "Epoch 193, Loss G: 0.2161, Loss D: -0.0185\n",
      "Epoch 194, Loss G: 0.2633, Loss D: 0.0080\n",
      "Epoch 195, Loss G: 0.2664, Loss D: -0.0157\n",
      "Epoch 196, Loss G: 0.2370, Loss D: -0.0140\n",
      "Epoch 197, Loss G: 0.1873, Loss D: -0.0183\n",
      "Epoch 198, Loss G: 0.2426, Loss D: -0.0017\n",
      "Epoch 199, Loss G: 0.2099, Loss D: -0.0294\n",
      "Epoch 200, Loss G: 0.1639, Loss D: -0.0169\n",
      "Epoch 201, Loss G: 0.2226, Loss D: -0.0392\n",
      "Epoch 202, Loss G: 0.1751, Loss D: -0.0001\n",
      "Epoch 203, Loss G: 0.1966, Loss D: -0.0052\n",
      "Epoch 204, Loss G: 0.2078, Loss D: -0.0114\n",
      "Epoch 205, Loss G: 0.2022, Loss D: -0.0133\n",
      "Epoch 206, Loss G: 0.1984, Loss D: -0.0284\n",
      "Epoch 207, Loss G: 0.1834, Loss D: -0.0225\n",
      "Epoch 208, Loss G: 0.2130, Loss D: -0.0399\n",
      "Epoch 209, Loss G: 0.1952, Loss D: -0.0111\n",
      "Epoch 210, Loss G: 0.1907, Loss D: -0.0071\n",
      "Epoch 211, Loss G: 0.1664, Loss D: -0.0196\n",
      "Epoch 212, Loss G: 0.1904, Loss D: -0.0020\n",
      "Epoch 213, Loss G: 0.2014, Loss D: -0.0313\n",
      "Epoch 214, Loss G: 0.1753, Loss D: -0.0042\n",
      "Epoch 215, Loss G: 0.1748, Loss D: 0.0040\n",
      "Epoch 216, Loss G: 0.1687, Loss D: -0.0133\n",
      "Epoch 217, Loss G: 0.2055, Loss D: -0.0265\n",
      "Epoch 218, Loss G: 0.1807, Loss D: -0.0205\n",
      "Epoch 219, Loss G: 0.1730, Loss D: -0.0083\n",
      "Epoch 220, Loss G: 0.1801, Loss D: -0.0262\n",
      "Epoch 221, Loss G: 0.1833, Loss D: -0.0217\n",
      "Epoch 222, Loss G: 0.1530, Loss D: -0.0338\n",
      "Epoch 223, Loss G: 0.1714, Loss D: -0.0193\n",
      "Epoch 224, Loss G: 0.1550, Loss D: -0.0366\n",
      "Epoch 225, Loss G: 0.1712, Loss D: -0.0167\n",
      "Epoch 226, Loss G: 0.1625, Loss D: -0.0241\n",
      "Epoch 227, Loss G: 0.1610, Loss D: -0.0185\n",
      "Epoch 228, Loss G: 0.1715, Loss D: -0.0146\n",
      "Epoch 229, Loss G: 0.1916, Loss D: -0.0261\n",
      "Epoch 230, Loss G: 0.1777, Loss D: -0.0240\n",
      "Epoch 231, Loss G: 0.2094, Loss D: -0.0155\n",
      "Epoch 232, Loss G: 0.1783, Loss D: -0.0266\n",
      "Epoch 233, Loss G: 0.2006, Loss D: -0.0392\n",
      "Epoch 234, Loss G: 0.1634, Loss D: -0.0050\n",
      "Epoch 235, Loss G: 0.1631, Loss D: -0.0288\n",
      "Epoch 236, Loss G: 0.1536, Loss D: -0.0194\n",
      "Epoch 237, Loss G: 0.1534, Loss D: -0.0166\n",
      "Epoch 238, Loss G: 0.1343, Loss D: -0.0228\n",
      "Epoch 239, Loss G: 0.1745, Loss D: -0.0158\n",
      "Epoch 240, Loss G: 0.1725, Loss D: -0.0310\n",
      "Epoch 241, Loss G: 0.1596, Loss D: -0.0304\n",
      "Epoch 242, Loss G: 0.1827, Loss D: -0.0205\n",
      "Epoch 243, Loss G: 0.1851, Loss D: -0.0338\n",
      "Epoch 244, Loss G: 0.1666, Loss D: -0.0302\n",
      "Epoch 245, Loss G: 0.1601, Loss D: -0.0160\n",
      "Epoch 246, Loss G: 0.1927, Loss D: -0.0144\n",
      "Epoch 247, Loss G: 0.1733, Loss D: -0.0234\n",
      "Epoch 248, Loss G: 0.1648, Loss D: -0.0272\n",
      "Epoch 249, Loss G: 0.1855, Loss D: -0.0155\n",
      "Epoch 250, Loss G: 0.1683, Loss D: 0.0004\n",
      "Epoch 251, Loss G: 0.1485, Loss D: -0.0107\n",
      "Epoch 252, Loss G: 0.1706, Loss D: -0.0065\n",
      "Epoch 253, Loss G: 0.1906, Loss D: -0.0171\n",
      "Epoch 254, Loss G: 0.1664, Loss D: -0.0280\n",
      "Epoch 255, Loss G: 0.1898, Loss D: -0.0268\n",
      "Epoch 256, Loss G: 0.1610, Loss D: -0.0326\n",
      "Epoch 257, Loss G: 0.1719, Loss D: -0.0265\n",
      "Epoch 258, Loss G: 0.1470, Loss D: -0.0373\n",
      "Epoch 259, Loss G: 0.1403, Loss D: -0.0274\n",
      "Epoch 260, Loss G: 0.1535, Loss D: -0.0300\n",
      "Epoch 261, Loss G: 0.1827, Loss D: -0.0127\n",
      "Epoch 262, Loss G: 0.1440, Loss D: -0.0168\n",
      "Epoch 263, Loss G: 0.1644, Loss D: -0.0171\n",
      "Epoch 264, Loss G: 0.1745, Loss D: -0.0141\n",
      "Epoch 265, Loss G: 0.1692, Loss D: -0.0239\n",
      "Epoch 266, Loss G: 0.2100, Loss D: -0.0231\n",
      "Epoch 267, Loss G: 0.1957, Loss D: -0.0282\n",
      "Epoch 268, Loss G: 0.1645, Loss D: -0.0101\n",
      "Epoch 269, Loss G: 0.1843, Loss D: -0.0258\n",
      "Epoch 270, Loss G: 0.1534, Loss D: -0.0258\n",
      "Epoch 271, Loss G: 0.2035, Loss D: 0.0011\n",
      "Epoch 272, Loss G: 0.1779, Loss D: -0.0116\n",
      "Epoch 273, Loss G: 0.1674, Loss D: -0.0184\n",
      "Epoch 274, Loss G: 0.1570, Loss D: -0.0124\n",
      "Epoch 275, Loss G: 0.1617, Loss D: -0.0197\n",
      "Epoch 276, Loss G: 0.1420, Loss D: -0.0079\n",
      "Epoch 277, Loss G: 0.1520, Loss D: -0.0337\n",
      "Epoch 278, Loss G: 0.1400, Loss D: -0.0192\n",
      "Epoch 279, Loss G: 0.1485, Loss D: -0.0108\n",
      "Epoch 280, Loss G: 0.1435, Loss D: -0.0120\n",
      "Epoch 281, Loss G: 0.1489, Loss D: -0.0232\n",
      "Epoch 282, Loss G: 0.1612, Loss D: -0.0312\n",
      "Epoch 283, Loss G: 0.1676, Loss D: -0.0390\n",
      "Epoch 284, Loss G: 0.1560, Loss D: -0.0342\n",
      "Epoch 285, Loss G: 0.1664, Loss D: -0.0223\n",
      "Epoch 286, Loss G: 0.1776, Loss D: -0.0189\n",
      "Epoch 287, Loss G: 0.1400, Loss D: -0.0100\n",
      "Epoch 288, Loss G: 0.1550, Loss D: -0.0194\n",
      "Epoch 289, Loss G: 0.1473, Loss D: -0.0315\n",
      "Epoch 290, Loss G: 0.1597, Loss D: -0.0309\n",
      "Epoch 291, Loss G: 0.1467, Loss D: -0.0321\n",
      "Epoch 292, Loss G: 0.1448, Loss D: -0.0250\n",
      "Epoch 293, Loss G: 0.1513, Loss D: -0.0269\n",
      "Epoch 294, Loss G: 0.1593, Loss D: -0.0181\n",
      "Epoch 295, Loss G: 0.1644, Loss D: -0.0259\n",
      "Epoch 296, Loss G: 0.1548, Loss D: -0.0192\n",
      "Epoch 297, Loss G: 0.1741, Loss D: -0.0139\n",
      "Epoch 298, Loss G: 0.1655, Loss D: -0.0164\n",
      "Epoch 299, Loss G: 0.1502, Loss D: -0.0299\n",
      "Epoch 300, Loss G: 0.1510, Loss D: -0.0234\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "\n",
    "ctgan.fit(file, discrete_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample creation\n",
    "\n",
    "samples = ctgan.sample(2758)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using bucket flood-prediction-master-dataset\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import tarfile\n",
    "\n",
    "import boto3 # AWS SDK for python. Provides low-level access to AWS services\n",
    "from sagemaker import get_execution_role\n",
    "import sagemaker\n",
    "\n",
    "m_boto3 = boto3.client('sagemaker') \n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "region = sess.boto_session.region_name\n",
    "\n",
    "bucket = 'flood-prediction-master-dataset'  #  specify the S3 bucket to save the file\n",
    "\n",
    "print('Using bucket ' + bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the file as csv locally\n",
    "\n",
    "samples.to_csv(\"gan_data_15_min.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send data to S3. key_prefix is the directory path. path is the local file name which will be saved in S3 with same file name\n",
    "# and bucket is the bucket name \n",
    "\n",
    "upload = sess.upload_data(path='gan_data_15_min.csv', bucket=bucket, key_prefix='ml-sensor-data-15-min/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
